{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b14565ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition\n",
    "import argparse\n",
    "import pickle\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2967283c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the argument parser and parse the arguments\n",
    "ap = argparse.ArgumentParser()\n",
    "ap.add_argument(\"--encodings\", required=True,help=\"path to serialized db of facial encodings\")\n",
    "ap.add_argument(\"--image\", required=True,help=\"path to input image\")\n",
    "ap.add_argument(\"--detection-method\", type=str, default=\"cnn\",help=\"face detection model to use: either `hog` or `cnn`\")\n",
    "args = vars(ap.parse_args([\"--encodings\",\"/Users/thejakamahaulpatha/PycharmProjects/Image Recognition/Project - Jurassic Park/encodings.pickle\",\"--image\",\"/Users/thejakamahaulpatha/PycharmProjects/Image Recognition/Project - Jurassic Park/examples/example2.jpeg\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ab523d1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading encodings...\n"
     ]
    }
   ],
   "source": [
    "# load the known faces and embeddings\n",
    "print(\"[INFO] loading encodings...\")\n",
    "data = pickle.loads(open(args[\"encodings\"], \"rb\").read())\n",
    "\n",
    "# load the input image and convert it from BGR to RGB\n",
    "image = cv2.imread(args[\"image\"])\n",
    "rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1f28563c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] recognizing faces...\n"
     ]
    }
   ],
   "source": [
    "# detect the (x, y)-coordinates of the bounding boxes corresponding \n",
    "# to each face in the input image, then compute the facial embeddings for each face\n",
    "\n",
    "print(\"[INFO] recognizing faces...\")\n",
    "boxes = face_recognition.face_locations(rgb,model=args[\"detection_method\"])\n",
    "encodings = face_recognition.face_encodings(rgb, boxes)\n",
    "\n",
    "# initialize the list of names for each face detected\n",
    "names = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "efc38403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over the facial embeddings\n",
    "for encoding in encodings:\n",
    "    # attempt to match each face in the input image to our known\n",
    "    # encodings\n",
    "    matches = face_recognition.compare_faces(data[\"encodings\"],encoding)\n",
    "    name = \"Unknown\"\n",
    "    \n",
    "    if True in matches:\n",
    "        \n",
    "\t\t# find the indexes of all matched faces then initialize a\n",
    "\t\t# dictionary to count the total number of times each face was matched\n",
    "        matchedIdxs = [i for (i, b) in enumerate(matches) if b]\n",
    "        counts = {}\n",
    "\t\t# loop over the matched indexes and maintain a count for\n",
    "\t\t# each recognized face face\n",
    "        for i in matchedIdxs:\n",
    "            name = data[\"names\"][i]\n",
    "            counts[name] = counts.get(name, 0) + 1\n",
    "\t\t# determine the recognized face with the largest number of\n",
    "\t\t# votes (note: in the event of an unlikely tie Python will\n",
    "\t\t# select first entry in the dictionary)\n",
    "        name = max(counts, key=counts.get)\n",
    "\t\n",
    "\t# update the list of names\n",
    "    names.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "65c7c9cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Unknown', 'ian_malcolm', 'ellie_sattler', 'alan_grant', 'john_hammond']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "97222793",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[37,\n",
       " 38,\n",
       " 39,\n",
       " 40,\n",
       " 42,\n",
       " 43,\n",
       " 44,\n",
       " 45,\n",
       " 46,\n",
       " 47,\n",
       " 48,\n",
       " 49,\n",
       " 50,\n",
       " 51,\n",
       " 52,\n",
       " 54,\n",
       " 55,\n",
       " 56,\n",
       " 57,\n",
       " 58,\n",
       " 59,\n",
       " 60,\n",
       " 61,\n",
       " 62,\n",
       " 63,\n",
       " 64,\n",
       " 65,\n",
       " 66,\n",
       " 67,\n",
       " 68,\n",
       " 69,\n",
       " 70,\n",
       " 71,\n",
       " 72,\n",
       " 73,\n",
       " 74,\n",
       " 76,\n",
       " 77,\n",
       " 78,\n",
       " 79,\n",
       " 80,\n",
       " 81,\n",
       " 82,\n",
       " 83,\n",
       " 84,\n",
       " 85,\n",
       " 86,\n",
       " 87,\n",
       " 88,\n",
       " 89,\n",
       " 91,\n",
       " 92,\n",
       " 93,\n",
       " 94,\n",
       " 95,\n",
       " 96,\n",
       " 97,\n",
       " 98,\n",
       " 152,\n",
       " 183,\n",
       " 192]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matchedIdxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "365ee588",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'john_hammond': 58, 'alan_grant': 3}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd91104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over the recognized faces\n",
    "for ((top, right, bottom, left), name) in zip(boxes, names):\n",
    "\t# draw the predicted face name on the image\n",
    "    cv2.rectangle(image, (left, top), (right, bottom), (0, 255, 0), 2)\n",
    "    y = top - 15 if top - 15 > 15 else top + 15\n",
    "    cv2.putText(image, name, (left, y), cv2.FONT_HERSHEY_SIMPLEX,0.75, (0, 255, 0), 2)\n",
    "\n",
    "# show the output image\n",
    "cv2.imshow(\"Image\", image)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e25df6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
